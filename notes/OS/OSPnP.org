#+TITLE: Operating Systems: Principles And Practice
#+OPTIONS: num:nil toc:nil

* Operating System Basics
** What is OS
*** Three roles of OS:
    - Referee
  
    Manage resources, protect applications from each other and protect
    itself.

    - Illusionist

    Provide the illusion of nearly infinite memory and exclusive use
    of the processor.

    - Glue

    Provide a set of common services that facilitate sharing among
    applications and separate applications from I/O hardware.

*** Sharing issues:
    - Resource allocation.
    - Isolation
    - Communication

    Virtualization Provides an applications with the illusion of
    resources that are not physically present.

** Operating System Evaluation.
*** Reliability and Availability.
    Reliability means that a system does exactly what it is designed
    to do. Availability is the percentage of time that the system is
    usable.

*** Security.
    Security means that the computer's operation cannot be compromised
    by a malicious attacker. Privacy is an aspect of security: data
    stored on the computer is only accessible to authorized users.

*** Portability.
    All operating systems provide applications with an abstraction of
    the underlying computer hardware; a *portable* abstraction is one
    that does not change as the hardware changes. *Abstract Virtual
    Machine(AVM)* is the interface provided by os to applications,
    including: 1)the *application programming interface(API)*, the list
    of system calls the os provides to applications, 2) the memory
    access model, 3) which instructions can be legally
    executed. *Hardware Abstraction Layer(HAL)* is the interface
    between OS and hardware.


* The Kernel Abstraction
** The Process Abstraction
   To run the program, the OS copies the instructions and data from
   the executable image into physical memory. The OS sets aside a
   memory region, *the execution stack*, to hold the state of local
   variables during procedure calls. The OS also sets aside a memory
   region, called *the heap*, for any dynamically allocated data
   structures the program might need. Thus, a process is an instance
   of a program. The OS keeps track of the various processes on the
   computer using a data structure called the *Process Control
   Block*. The PCB stores all the information the OS needs about a
   particular process: where it is stored in memory, where its
   executable image resides on disk, which user asked it to execute,
   what privileges the process has, and so forth.

** Dual-Mode Operation
   The processor has 2 modes: *User mode*, in which the processor
   checks each instruction to verify that it is permitted and *Kernel
   mode*, in which the processor doesn't perform any checks.
   Dual-Mode require 3 things:
   - Privileged Instructions
   - Memory Protection (Virtual memory)
   - Timer Interrupts

** Types of Mode Transfer
*** User to Kernel Mode
    There are 3 reasons for the kernel to take control from a user
    process:

    - *Interrupts*

      *An interrupt* is an asynchronous signal to the processor that
      some external event has occurred that may require its
      attention. If an interrupt happens the processor hardware saves
      the current execution state and starts executing *interrupt
      handler* in the kernel.

    - *Processor exceptions*

      *A processor exception* is a hardware event caused by user
      program behavior that causes a transfer of control to the
      kernel. The hardware finishes all previous instructions, saves
      the current execution state, and starts running *exception
      handler* in the kernel.

    - *System Calls*

      *A system call* is any procedure provided by the kernel that can
      be called from user level.

*** Kernel to User Mode
    - *New process.*

      To start a new process, the kernel copies the program into
      memory, sets the program counter to the first instruction of the
      process, sets the stack pointer to the base of the user stack,
      and switches to user mode.

    - *Resume after an interrupt, processor exception, or system call*

      When the kernel finishes handling the request, it resumes
      execution of the interrupted process by restoring its program
      counter (in the case of a system call, the instruction after the
      trap), restoring its registers, and changing the mode back to
      user level.

    - *Switch to a different process*

      Sometimes(such as on a timer interrupt) the kernel switches to a
      different process than the one that had been running before the
      interrupt. Since the kernel will eventually resume the old
      process, the kernel needs to save the process state - its
      program counter, registers, and so forth - in the process's
      control block. The kernel can then resume a different process by
      loading its state from the process's control block into the
      processor and then switching to user mode.

    - *User-level upcall*

** Implementing Safe Mode Transfer
*** Interrupt Vector Table
    The processor has a special register that points to an area of
    kernel memory called the *interrupt vector table*. The interrupt
    vector table is an array of pointers, with each entry pointing to
    the first instruction of a different handler procedure in the
    kernel.

*** Interrupt Stack
    Privileged hardware register points to a region of kernel memory
    called the interrupt stack. When an interrupt, processor
    exception, or system call trap causes a context switch into the
    kernel, the hardware changes the stack pointer to point to the
    base of the kernel's interrupt stack.

*** Two Stacks per Process
    Most OS kernels allocate a kernel interrupt stack for every
    user-level process.

*** Interrupt Masking
    To simplify the kernel design, the hardware provides a privileged
    instruction to temporarily defer delivery of an interrupt until it
    is safe to do so.

*** Hardware Support for Saving and Restoring Registers
    1) Processor pushes the interrupted process's stack pointer onto the kernel's interrupt stack.
    2) Then pushes the interrupted process's instruction pointer.
    3) Then the processor status word.
    Also there are instructions (pushad, pusha), to save the remaining
    registers onto the stack.

*** X86 Mode Transfer
    1) Mask interrupts.
    2) Save three key values: Stack pointer,
       Instruction pointer, Execution flags to internal, temporary
       hardware registers.
    3) Switch onto the kernel interrupt stack.
    4) Push the three key values onto the interrupt stack.
    5) Save an error code or push a dummy value onto the stack.
    6) Invoke the interrupt handler.

*** Implementing Secure System Calls
    1) The user program calls the user stub in the normal way, oblivious
       to the fact the implementation of the procedure is in fact in
       the kernel.

    2) The user stub fills in the code for the system call and executes
       the trap instruction.

    3) The hardware transfers control to the kernel, vectoring to the
       system call handler.

       The handler acts as a stub on the kernel side, copying and
       *checking arguments* and then calling the kernel implementation
       of system call.

    4) After the system call completes, it returns to the handler.

    5) The handler returns to user level at the next instruction in the stub.

    6) The stub returns to the caller.

** Starting a New Process
   The kernel must:
   - Allocate and initialize the process control block.

   - Allocate memory for the process.

   - Copy the program from disk into the newly allocated memory.

   - Allocate a user-level stack for user-level execution.

   - Allocate a kernel-level stack for handling sys calls, interrupts and
     processor exceptions.

   - Copy arguments into user memory.

     Arguments to a process are copied to the base of the user-level
     stack, and the user's stack pointer is incremented so those
     addresses are not overwritten when the program starts running.

   - Transfer control to user mode.

     The kernel allocate a kernel stack to create the new process, and
     reserve room at the bottom of the kernel stack for the initial
     values of its user-space registers, program counter, stack
     pointer, and processor status word. To start the new program, the
     kernel switch to the new stack and jump to the end of the
     interrupt handler.

   The compiler puts a stub at the location in the process's memory
   where the kernel will jump when the process starts. The stub's job
   is to call main and then, if main returns, to call exit(sys call to
   terminate the process).

** Implementing Upcalls
   There are several uses for immediate event delivery with upcalls:
   - *Preemptive user-level threads.*

     A user-level thread package can use a periodic timer upcall as a
     trigger to switch task.

   - *Asynchronous I/O notification.*

     A sys call starts the request and returns immediately. Later, the
     application can poll kernel for I/O completion, or a separate
     notification can be sent via an upcall.

   - *Interprocess communication.*

     A kernel upcall is needed if a process generates an event that
     need the instant attention of another process.

   - *User-level exception handling.*

     The OS needs to inform the application when it receives a
     processor exception so the application runtime handles the event.
     User-level resource allocation.

   UNIX signal share many similarities with hardware interrupts:
   - Types of signals.
   - Handlers.

     Each process defines its own handlers for each signal type.
   - Signal stack.
   - Signal masking.
   - Processor state.

   To deliver the timer interrupt to user level, the kernel copies
   that saved state to the bottom of the signal stack, resets the
   saved state to point to the signal handler and signal stack, and
   then exits the kernel handler. The iret instruction then resumes
   user-level execution at the signal handler. When the signal handler
   returns, these steps are


* The Programming Interface
  Where each function is implemented is up to the OS, based on a
  tradeoff between flexibility, reliability, performance, and safety.

** Process Managment
*** Unix fork
    - Create and initialize the process control block in the kernel
    - Create a new address space
    - Initialize the address space with a copy of the entire contents of
      the address space of the parent
    - Inherit the execution context of the parent
    - Inform the scheduler that the new process is ready to run
*** Unix exec and wait
    *exec*:
    - Load the program prog into the current address space
    - Copy arguments args into memory in the address space
    - Initialize the hardware context to start execution at start

    *wait*:

    Pauses the parent until the child finishes, crashes, or is
    terminated.

** Input/Output
   The basic ideas in the UNIX I/O interface are:
   - Uniformity.

     Al device I/O use the same set of system calls: open, close, read
     and write.

   - Open before use

     This gives the OS a chance to check access permissions and to set
     up any internal bookkeeping. Open returns a handle to be used in
     later calls to read, write and close to identify the file, device
     or channel.

   - Byte-oriented

     All devices are accessed with byte arrays.

   - Kernel-buffered reads.

     Stream data is stored in a kernel buffer and returned to the
     application on request. This allows the UNIX system call read
     interface be the same for devices with streaming reads as those
     with block reads. If no data is available to be returned, the
     read call blocks until it arrives.

   - Kernel-buffered writes.

     Outgoing data is stored in a kernel buffer for transmission when
     the device becomes available. The system call write copies the
     data into the kernel buffer and returns immediately. But if the
     application generates data faster than the device can receive it,
     the write system call blocks in the kernel until there is enough
     room to store the new data in the buffer.

   - Explicit close

     When an application is done with I/O, it calls close. This
     signals to the OS that it can decrement the reference-count on
     the device, and garbage collect any unused kernel data
     structures.

*** Interprocess Communication (IPC)
    For IPC, we need a few more concepts:
    - Pipes

      A UNIX pipe is a kernel buffer with two file descriptors, one
      for writing and one for reading. The pipe terminates when either
      endpoint closes the pipe or exits.

    - Replace file descriptor

      By manipulating the file descriptors of the child process, the
      shell can cause the child to read its input from, or send its
      output to, a file or a pipe instead of soome a keyboard or to
      the screen.

      System call named /dup2(from, to)/ replaces the to file
      descriptor with a copy of the from file descriptor.

    - Wait for multiple reads.

      The UNIX system call /select(fd[], number)/ allows the
      application to wait for input from any of a set of file
      descriptors; it returns the file descriptor that has data, but
      it doesn't read the data.

*** Summarizes the dozen UNIX system calls.
    *Creating and managing processes*

    | /fork()/                          | Create a child process as a clone of the current process. |
    | /exec(prog, args)/                | Run the application prog in the current process.          |
    | /exit()/                          | Tell the kernel the current process is complete.          |
    | /wait(pid)/                       | Pause until the child process has exited.                 |
    | /signal(pid, type)/               | Send an interrupt of a specified type to a process.       |

    *I/O operations*

    | /fd open(name)/               | Open a file, channel, or device.                   |
    | /pipe(fd[2])/                 | Create a one-dir pipe.                             |
    | /dup2(from, to)/              | Replace the to fd with a copy of from.             |
    | /int read(fd, buffer, size)/  | Read up to size bytes into buffer.                 |
    | /int write(fd, buffer, size)/ | Write up to size bytes into kernel output buffer.  |
    | /fd select(fd[], count)/      | Return when any fd have data available to be read. |
    | /close(fd)/                   | Thell the kernel the process is done with I/O      |






* Concurrency and Threads
** Thread Abstraction

   A _thread_ is a single execution sequence that represent a
   separately schedulable task.

** Simple Threads API
| func                                  | description                                         |
|---------------------------------------+-----------------------------------------------------|
| void thread_create(thread, func, arg) | Create a new thread                                 |
| void thread_yield()                   | Gives up the processor to let some other thread run |
| int thread_join(thread)               | Wait for thread to finish, return exit code         |
| void thread_exit(ret)                 | Finish the current thread.                          |

** Thread Data Structures
*** Per-Thread State and Thread Control Block
    _Thread Control Block(TCB)_ is a data structure that represent a
    thread's state.

    TCB holds two types of per-thread info:
    - The state of the computation being performed by the
      thread(Stack, registers).
    - Metadata about the thread that is used to mange the
      thread(Thraed ID, scheduling priority, status, etc.).


*** Shared State
    - Code
    - Global Variables
    - Heap

** Thread life Cycle

   1) *INIT*

      Allocates and initializes TCB.  After that thread creation code
      puts the thrread into the READY state.

   2) *READY*

      A thread in the READY state is abailable to be run but is not
      currently running.  At any time, the scheduler can switch state
      to RUNNING, by coping state to a processor's registers.


   3) *RUNNING*

      - Switch to WAITING (join)
      - Switch to READY (yield)
      - Switch to FIHISHED (exit)

   4) *WAITING*

      A thread in the WAITING state is waiting for some event, then
      switch to READY state.

   5) *FINISHED*

** Implementing Kernel Threads
   There are three steps to creating a thread:

   1) *Allocete per-thread state.*
   2) *Initialize per-thread state.*
   3) *Put TCB on ready list.*

   There are two steps to deleting the thread:

   1) *Remove the thread from the ready list.*
   2) *Free the per-thread state allocated for the thread.*

   A thread never deletes its own state, some other thread must do it.

** Combining Kernel Threads and Single-Threaded User Processes
   Since the PCB and TCB each represent one thread, the kernel's ready
   list can contain a mix of PCBs(user processes) and TCBs(kernel
   threads).

** Implementing Multi-Threaded Processes

   - *Implementing Multi-Threaded Processes Usning Kernel Threads*

     To create a thread, the user lib alloc a user-level stack and
     than does a syscall.  The kernel alloc a TCB and interrupt
     stack. Then the kernel puts the new thread on the ready list, and
     return unique id for the user program.

     Thread join, yiel, and exit work the same way: by syscall with
     id.

   - *Implementing User-Level Threads Without Kernel Support*



* Sync Access to Shared Objects
** Challenges
*** Race Conditions
    A _race condition_ occurs when the behavior of a program depends
    on the interleaving of operations of different threads. In effect,
    the result of execution depends on who wins the race.

** Structuring Shared Objects
   _Shared objects_ are objects that can be accessed by multiple
   threads.

*** Implementing Shared Objects
    - *Shared object layer.*
      
      API.
      
    - *Synchronization variable layer.*

      Shared objects include sync vars as member variables.  A
      _Synchronization variable(Sync var)_ is a data struct used for
      coordinating concurrent access to shared state. Sync vars can be
      two types: /locks/ and /condition variables/. Sync vars
      coordinate access to _state variables_, which are just normal
      member vars.

    - *Atomic instruction layer.*

      Modern implementations build sync vars using 
      _atomic read-modify-write instructions_.

** Locks: Mutual Exclusion(mutex)
   A _lock_ is a sync var that provides mutual exclusion(when one
   thread holds a lock, no other can hold it)

*** Locks: API and Properties
    Lock provide two funcs acquire() and release().

    - A lock can be in one of two states: BUSY or FREE
    - A lock is initially in FREE state
    - acquire waits until the lock is FREE and then atomically makes
      the lock BUSY.
    - release makes the lock FREE.

** Condition Variables: Waiting for a Change
   A _Condition variable_ is a sync object that lets a thread wait for
   a change to shared state that is protected by a lock.
   
   - *wait(Lock *lock)*
     
     This call atomically releases the lock and suspends execution of
     the calling thread, placing the calling thread on the condition
     variable's waiting list. When the calling thread is re-enabled,
     it reacquires the lock before returning from the wait call.

   - *signal()*

     This call takes one thread off the condition variale's waiting
     list and marks it as eligible to run.

   - *broadcast()*

     This call takes all threads off the condition variable's waiting
     list and marks them as eligible to run.

** Designing and Implementing Shared Objects
*** High Level Methodology   
    Steps needed for the multi-threaded shared object:
	1. Add a lock.
	2. Add code to /acquire/ and /release/ the lock.
	3. Identify and add condition variables.
	4. Add loops to wait using the condition variables.
	5. Add /signal/ and /broadcast/ calls.

*** Implementation Best Practices
	1. Consistent structure.

	   Frees you to focus on the core problem because the details of
	   the standard approach become a habbit, and makes it easier for
           those who follow to weview, maintain, and debug your code.

	2. Always synchronize with locks and condition variables.

	   That means don't use semaphores.

	3. Always acquire the lock at the beginning of a method and
	   release it right before the return

	   Don't acquire the lock in the middle of the function.
	   Don't acquire the lock in one function(or thread) and rlease it
	   in another.

	4. Always wait in a while loop (Mesa style).

	5. (Almost) never use thread_sleep.

	   !!!

	6. Always hold the lock when operating on a condition variables.

*** Three Pitfalls
	1. Double-Checked Locking.
	2. Avoid defining a sync block in the middle of a method (Java).
	3. Keep shared state classes separate from thread classes (Java).
** Implementing Synchronization Objects
** Summary
   - *Race conditions.*
   - *Locks and conditions variables.*
   - *A methodology for writing shared objects.*
   - *Semaphores.*
	 


* Multi-Object Synchronization
** Multiprocessor Lock Performance
   Multi-Objcet sync issuse:

   1. Locking

      Only one thread at a time can hold the lock.

   2. Communication of shared data
      
      Shared data protected by a lock will often need to be copied
      from one cache to another.
      
   3. False sharing

** Lock Design Patterns
   Four design patterns to increase concurrency when it is necessary:

*** Fine-Grained Locking
    The idea of fine-grained lock is to partition the shared object's
    state into different subsets, each protected by its own lock.

*** Per-Processor Data Structures
    ...

*** Ownership Design Pattern
    In this pattern, a thread removes an object from a container and
    can then access the object without holding a lock: the program
    structure guarantees that at most one thread owns an object at a
    time.

*** Staged Architecture
    The staged architecture pattern divides a system into multiple
    subsystems, called stages. Each stage includes stage private to
    the stage and a set of one or more worker threads that operate on
    that state.


* Scheduling
** Uniprocessor Scheduling
  - FIFO
  - Shortest Job First (SJF)
  - Round Robin
*** Multi-Level Feedback Queue (MFQ)
    MFQ has multiple Round Robin queues, each with a different
    priority level and time quantum.





* Address Translation

* Caching and Virtual Memory

* Advenced Memory Management




* File Systems: Introduction and Overview
